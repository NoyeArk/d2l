{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T06:31:32.043069Z",
     "start_time": "2024-10-27T06:31:17.097140Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import d2l.torch as d2l\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\anaconda3\\envs\\DeltaZero\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "F:\\anaconda\\anaconda3\\envs\\DeltaZero\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T02:12:03.567518Z",
     "start_time": "2024-10-27T02:12:03.539280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "train_data"
   ],
   "id": "150f528ef9e67f65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  image                    label\n",
       "0          images/0.jpg         maclura_pomifera\n",
       "1          images/1.jpg         maclura_pomifera\n",
       "2          images/2.jpg         maclura_pomifera\n",
       "3          images/3.jpg         maclura_pomifera\n",
       "4          images/4.jpg         maclura_pomifera\n",
       "...                 ...                      ...\n",
       "18348  images/18348.jpg          aesculus_glabra\n",
       "18349  images/18349.jpg  liquidambar_styraciflua\n",
       "18350  images/18350.jpg            cedrus_libani\n",
       "18351  images/18351.jpg      prunus_pensylvanica\n",
       "18352  images/18352.jpg          quercus_montana\n",
       "\n",
       "[18353 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/0.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/1.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/2.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/3.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/4.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18348</th>\n",
       "      <td>images/18348.jpg</td>\n",
       "      <td>aesculus_glabra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18349</th>\n",
       "      <td>images/18349.jpg</td>\n",
       "      <td>liquidambar_styraciflua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18350</th>\n",
       "      <td>images/18350.jpg</td>\n",
       "      <td>cedrus_libani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18351</th>\n",
       "      <td>images/18351.jpg</td>\n",
       "      <td>prunus_pensylvanica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18352</th>\n",
       "      <td>images/18352.jpg</td>\n",
       "      <td>quercus_montana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18353 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class LeaveDataset(Dataset):\n",
    "    def __init__(self, x, y, train=True):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.train = train\n",
    "        self.train_transpose = v2.Compose([\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomVerticalFlip(),\n",
    "            v2.RandomRotation(180, fill=(255, 255, 255)),\n",
    "            v2.ColorJitter(0.5),\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.PILToTensor(),\n",
    "            v2.ToDtype(torch.float32),\n",
    "            v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.test_transpose = v2.Compose([\n",
    "            v2.Resize((224, 224)),\n",
    "            v2.PILToTensor(),\n",
    "            v2.ToDtype(torch.float32),\n",
    "            v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.data_path = \"data/images/\"\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        x = Image.open(self.data_path + x)\n",
    "        x = self.train_transpose(x) if self.train else self.test_transpose(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ],
   "id": "bd4ad3a4e4ec0623",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 加载训练数据集\n",
    "x, y = train_data['image'], train_data['label']\n",
    "x, y"
   ],
   "id": "f7d2affd4b27f04e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0            images/0.jpg\n",
       " 1            images/1.jpg\n",
       " 2            images/2.jpg\n",
       " 3            images/3.jpg\n",
       " 4            images/4.jpg\n",
       "                ...       \n",
       " 18348    images/18348.jpg\n",
       " 18349    images/18349.jpg\n",
       " 18350    images/18350.jpg\n",
       " 18351    images/18351.jpg\n",
       " 18352    images/18352.jpg\n",
       " Name: image, Length: 18353, dtype: object,\n",
       " 0               maclura_pomifera\n",
       " 1               maclura_pomifera\n",
       " 2               maclura_pomifera\n",
       " 3               maclura_pomifera\n",
       " 4               maclura_pomifera\n",
       "                   ...           \n",
       " 18348            aesculus_glabra\n",
       " 18349    liquidambar_styraciflua\n",
       " 18350              cedrus_libani\n",
       " 18351        prunus_pensylvanica\n",
       " 18352            quercus_montana\n",
       " Name: label, Length: 18353, dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_train_data():\n",
    "    data = pd.read_csv('data/train.csv')\n",
    "    x, y = data['image'], data['label']\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.1, random_state=66, shuffle=True, stratify=y)\n",
    "    \n",
    "    train_ds, valid_ds = LeaveDataset(train_x.values, train_y), LeaveDataset(valid_x.values, valid_y)\n",
    "    \n",
    "    train_dl, valid_dl = DataLoader(train_ds, batch_size=128, shuffle=False, num_workers=3, persistent_workers=True), DataLoader(valid_ds, batch_size=128, shuffle=False, num_workers=3, persistent_workers=True)\n",
    "    print(f'train={len(train_dl)}, valid={len(valid_dl)}')\n",
    "    \n",
    "    return train_dl, valid_dl, le"
   ],
   "id": "e12b1695ec367a09",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_data, valid_data, le = load_train_data()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "id": "4af2be80f3d4dfbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=130, valid=15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T02:12:04.525498Z",
     "start_time": "2024-10-27T02:12:03.664326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(128, len(le.classes_))\n",
    ")\n",
    "model.to(device)\n",
    "model"
   ],
   "id": "b24b129833447bfc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=176, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-27T02:12:42.345380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, valid_loss = [], []\n",
    "    train_acc, valid_acc = [], []\n",
    "    \n",
    "    # 训练模型\n",
    "    model.train()\n",
    "    for x, y in train_data:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        l = loss(y_hat, y)\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        train_loss.append(l.item())\n",
    "        train_acc.append(d2l.Classifier().accuracy(y_hat, y).item())\n",
    "\n",
    "    # 测试模型\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_data:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            l = loss(y_hat, y)\n",
    "\n",
    "            valid_loss.append(l.item())\n",
    "            valid_acc.append(d2l.Classifier().accuracy(y_hat, y).item())\n",
    "\n",
    "    print(f'{epoch}:'\n",
    "      f'train_l={np.mean(train_loss):.6f},train_acc={np.mean(train_acc):.6f},'\n",
    "      f'valid_l={np.mean(valid_loss):.6f},valid_acc={np.mean(valid_acc):.6f}')"
   ],
   "id": "34b168a20beaa612",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a75185298525e720"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
